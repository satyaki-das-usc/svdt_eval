seed: 7
num_workers: 8
log_offline: false

# preprocess keys
joern_path: "joern/joern-parse"
split_token: false

# data keys
data_folder: "C/test_data"
save_every_epoch: 1
val_every_epoch: 1
log_every_epoch: 10
progress_bar_refresh_rate: 1

cfg_folder: "cfg_db"
pdg_folder: "pdg_db"
call2cfgNode_folder: "dict_call2cfgNodeID_funcID"

slice_folder: "slices"
label_folder: "label_source"
slice_label_folder: "slice_label"
clean_slice_folder: "clean_slices"

ground_truth_filename: "ground_truth.txt"

source2slice_folder: "source2slice"
hash_folder: "hash_slices"
deletelist_folder: "delete_list"
corpus_folder: "corpus"
w2v_model_folder: "w2v_model"
w2v_modelname: "wordmodel3"
vector_folder: "vector"
dl_input_folder: "dl_input/cdg_ddg"
dl_input_shuffle_folder: "dl_input_shuffle/cdg_ddg"

dataset:
  name: CWE119
  token:
    max_parts: 16
    is_wrapped: false
    is_splitted: false
    vocabulary_size: 190000

gnn:
  # gcn, ggnn
  name: "gcn"
  w2v_path: "${data_folder}/${dataset.name}/w2v.wv"
  embed_size: 256
  hidden_size: 256
  pooling_ratio: 0.8
  drop_out: 0.5
  n_hidden_layers: 3
  n_head: 3
  n_gru: 3
  edge_sample_ratio: 0.8
  rnn:
    hidden_size: 256
    num_layers: 1
    drop_out: 0.5
    use_bi: true
    activation: relu

classifier:
  hidden_size: 512
  n_hidden_layers: 2
  n_classes: 2
  drop_out: 0.5

hyper_parameters:
  vector_length: 128

  n_epochs: 50
  patience: 10
  batch_size: 64
  test_batch_size: 64
  reload_dataloader: true
  clip_norm: 5
  val_every_step: 1.0
  log_every_n_steps: 50
  progress_bar_refresh_rate: 1
  resume_from_checkpoint: null
  shuffle_data: true

  optimizer: "Adam"
  nesterov: true
  learning_rate: 0.002
  weight_decay: 0
  decay_gamma: 0.95